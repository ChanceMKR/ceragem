{"cells":[{"cell_type":"markdown","id":"bc0708d7","metadata":{"id":"bc0708d7"},"source":["## Mas Link"]},{"cell_type":"code","execution_count":null,"id":"113b8f07","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"id":"693decb1","metadata":{"id":"693decb1"},"outputs":[],"source":["import time\n","import random\n","import re\n","import os\n","import csv\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","from datetime import datetime, timedelta\n","\n","import urllib.request # URL requests\n","import urllib.parse # URL parsing\n","\n","import requests # HTTP requests\n","from bs4 import BeautifulSoup as bs # HTML parsing\n","\n","from selenium import webdriver # Chromedriver\n","from selenium.webdriver.common.by import By # HTML element 선택\n","from selenium.webdriver.common.keys import Keys # 키보드 키 입력 위함\n","from selenium.webdriver.common.desired_capabilities import DesiredCapabilities # 크롬 옵션 설정\n","from selenium.common.exceptions import UnexpectedAlertPresentException # 예외 처리 위함\n","from selenium.common.exceptions import (\n","    NoSuchElementException, \n","    InvalidSessionIdException, \n","    InvalidArgumentException, \n","    TimeoutException, \n","    WebDriverException, \n","    StaleElementReferenceException\n",")"]},{"cell_type":"code","execution_count":2,"id":"facc0b0d","metadata":{},"outputs":[],"source":["# 키워드\n","project_name = '세라젬'\n","url_path = './0.크롤링/blind_url'\n","channel = '블라인드'\n","save_path = './0.크롤링/result'\n","name = '성찬'\n","\n","keyword = ['건강']"]},{"cell_type":"code","execution_count":3,"id":"a35ddb01","metadata":{"id":"a35ddb01"},"outputs":[],"source":["driver = webdriver.Chrome() # 크롬드라이버 객체 생성(초기화)\n","driver.implicitly_wait(3) # 암묵적 대기(3초)\n","\n","# url 폴더 생성\n","if not os.path.exists(url_path):\n","    os.makedirs(url_path)\n","\n","# 키워드 검색후 url 수집\n","for word in keyword:\n","    url_list=[]\n","    date_list=[]\n","    driver.get('https://www.teamblind.com/kr/search/'+word) # '키워드' 검색\n","    \n","    # 추천순 버튼 클릭\n","    button = driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div/div[3]/div[2]/span/a')\n","    button.click()\n","\n","    # 최신순 버튼 클릭\n","    button = driver.find_element(By.XPATH, '//*[@id=\"search_sort\"]/a[2]')\n","    button.click()\n","\n","    # 페이지 끝까지 내리기\n","    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n","    while True:\n","        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","        time.sleep(random.uniform(1,1.7))\n","        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n","        if new_height == last_height:\n","            break\n","\n","        last_height = new_height\n","\n","    # 검색결과 url과 날짜 수집\n","    url_elements = driver.find_elements(By.CSS_SELECTOR, \".pv\")  # .pv: 검색결과의 제목\n","    date_elements = driver.find_elements(By.CSS_SELECTOR, \".past\")  # 날짜를 포함한 요소\n","\n","    for url_element, date_element in zip(url_elements, date_elements):\n","        url = url_element.get_attribute('href')  # href(링크 주소) 속성값 가져오기\n","        date = date_element.text  # 날짜 텍스트 가져오기\n","        \n","        #샘플용\n","        if len(url_list) <= 300:\n","            url_list.append(url)\n","            date_list.append(date)\n","        else:\n","            break\n","\n","    # 데이터프레임으로 저장\n","    url_save = pd.DataFrame({\n","        'keyword': [word] * len(url_list),\n","        'url': url_list,\n","        'date': date_list\n","    })\n","    \n","    file_path = os.path.join(url_path, f'[{project_name}]{word}_{channel}_url.csv')\n","    url_save.to_csv(file_path, index=False)\n","\n","driver.quit()"]},{"cell_type":"markdown","id":"58fbffeb","metadata":{"id":"58fbffeb"},"source":["## Crawling"]},{"cell_type":"code","execution_count":4,"id":"1f4299db","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["키워드: 건강 전처리 시작\n"]}],"source":["import re\n","import os\n","import pandas as pd\n","\n","# 패턴\n","pattern_2022_2023 = re.compile(r'^(2022|2023)\\.\\d{2}\\.\\d{2}\\.?$')\n","pattern_2024 = re.compile(r'^2024\\.(01|02|03|04)\\.\\d{2}\\.?$')\n","\n","# 날짜 형식 확인 및 변환 함수\n","def check_and_format_date(date_text):\n","    if isinstance(date_text, float) or isinstance(date_text, int):\n","        return None\n","\n","    # '작성시간' 한글 제거\n","    date_text = date_text.replace('작성시간', '').strip()\n","    \n","    # '분', '시간', '일'이 포함된 데이터 무시\n","    if '분' in date_text or '시간' in date_text or '일' in date_text:\n","        return None\n","    \n","    # 'MM.DD' 형식의 데이터 처리\n","    if re.match(r'^\\d{2}\\.\\d{2}$', date_text):\n","        date_text = f\"2024.{date_text}\"\n","\n","    # 최종 날짜 형식 처리\n","    if pattern_2022_2023.match(date_text) or pattern_2024.match(date_text):\n","        return date_text\n","    return None\n","\n","# url 폴더 생성\n","if not os.path.exists(url_path + '/processed'):\n","    os.makedirs(url_path + '/processed')\n","\n","# 크롤링된 CSV 파일을 불러와서 전처리\n","for word in keyword:\n","    print('키워드:', word, '전처리 시작')\n","\n","    # 크롤링된 CSV 파일 불러오기\n","    url_file_path = os.path.join(url_path, f'[{project_name}]{word}_{channel}_url.csv')\n","    data = pd.read_csv(url_file_path)\n","    \n","    # 날짜 형식 확인 및 변환\n","    data['date'] = data['date'].apply(check_and_format_date)\n","\n","    # None 값 제거 (날짜가 지정된 범위에 속하지 않는 데이터 제거)\n","    data = data.dropna(subset=['date'])\n","\n","    # 데이터프레임을 CSV 파일로 저장\n","    processed_file_path = os.path.join(url_path + '/processed', f'[{project_name}]{word}_{channel}_url_processed.csv')\n","    data.to_csv(processed_file_path, index=False)"]},{"cell_type":"code","execution_count":3,"id":"3e1fea53","metadata":{"id":"3e1fea53","outputId":"93a7e7b2-91f3-4219-d68b-50d713ed8ae2"},"outputs":[],"source":["driver = webdriver.Chrome() # 크롬드라이버 객체 생성(초기화)\n","driver.implicitly_wait(3) # 암묵적 대기(3초)\n","\n","url = 'https://www.teamblind.com/kr/'\n","driver.get(url) # URL 접속\n","\n","# 이 셀까지 진행한 후 드라이버에 직접 로그인(인증번호) 필요!"]},{"cell_type":"code","execution_count":6,"id":"6e2c48fc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Session ID: 3e9298c4c90f3e20f678aba81531a09d\n","Executor URL: http://localhost:58273\n"]}],"source":["# # Capture the session_id and executor_url\n","# session_id = driver.session_id\n","# executor_url = driver.command_executor._url\n","\n","# print(f\"Session ID: {session_id}\")\n","# print(f\"Executor URL: {executor_url}\")"]},{"cell_type":"code","execution_count":8,"id":"0ed4702a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["키워드: 건강 크롤링 시작\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab1903830ff94d12b160ede529caac13","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# url 폴더 생성\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path)\n","    \n","# 크롤링 시작\n","for word in keyword:\n","    print('키워드:', word, '크롤링 시작')\n","\n","    # url_csv 불러오기\n","    processed_file_path = os.path.join(url_path + '/processed', f'[{project_name}]{word}_{channel}_url_processed.csv')\n","    url_list = pd.read_csv(processed_file_path)\n","\n","    # 크롤링 결과 저장할 리스트 생성\n","    pre_board_list = []\n","    post_board_list = []\n","    title_list = []\n","    date_list = []\n","    content_list = []\n","    review_list = []\n","    keyword_list = []\n","    channel_list = []\n","\n","    # url_list 크롤링\n","    for url in tqdm(url_list['url']):\n","        try:\n","            driver.get(url)\n","            driver.implicitly_wait(3)\n","            time.sleep(random.uniform(1, 1.7))\n","\n","            # 날짜 추출\n","            formatted_date = url_list[url_list['url'] == url]['date']\n","\n","            # 게시판 이름 추출\n","            pre_board = driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[2]/div[1]/h1/a[1]')\n","            pre_board_text = pre_board.text\n","\n","            try:\n","                post_board = driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[2]/div[1]/h1/a[2]')\n","                post_board_text = post_board.text\n","            except NoSuchElementException:\n","                post_board_text = None\n","\n","            # 제목 추출\n","            title = driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[2]/div[1]/h2')\n","            title_text = title.text\n","\n","            # 본문 추출\n","            content = driver.find_element(By.XPATH, '//*[@id=\"contentArea\"]')\n","            content_text = content.text\n","\n","            # 댓글 버튼 클릭\n","            try:\n","                if driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[2]/div[4]/button'):\n","                    while True:\n","                        driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[1]/div[4]/button').click()\n","                        time.sleep(0.5)\n","                        if not driver.find_element(By.XPATH, '//*[@id=\"wrap\"]/section/div/div[1]/div[4]/button'):\n","                            break\n","            except:\n","                pass\n","\n","            # 대댓글 더보기 클릭\n","            try:\n","                if driver.find_element(By.CSS_SELECTOR, '.btn-reply'):\n","                    re = 0\n","                    while True:\n","                        re += 1\n","                        driver.find_element(By.CSS_SELECTOR, '.btn-reply').click()\n","                        time.sleep(0.5)\n","                        if not driver.find_element(By.CSS_SELECTOR, '.btn-reply') or re == 20:\n","                            break\n","            except:\n","                pass\n","\n","            # 댓글 추출\n","            review_text = ''\n","            reviews = driver.find_elements(By.CSS_SELECTOR, '.cmt-txt')\n","            for review in reviews:\n","                try:\n","                    review_content = review.text\n","                    if review_content != '작성자가 삭제한 댓글입니다.':\n","                        review_text += ' ' + review_content\n","                except StaleElementReferenceException:\n","                    reviews = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.cmt-txt')))\n","\n","            # 리스트에 추가\n","            pre_board_list.append(pre_board_text)\n","            post_board_list.append(post_board_text)\n","            title_list.append(title_text)\n","            date_list.append(formatted_date)\n","            content_list.append(content_text)\n","            review_list.append(review_text)\n","            keyword_list.append(word)\n","            channel_list.append(channel)\n","\n","        except (InvalidSessionIdException, InvalidArgumentException, WebDriverException, NoSuchElementException) as e:            \n","            print(f\"Invalid URL: {url}\")\n","            continue\n","\n","    # 데이터프레임 생성 및 CSV 저장\n","    data = pd.DataFrame({\n","        '채널': channel_list,\n","        '키워드': keyword_list,\n","        '게시판_대분류': pre_board_list,\n","        '게시판_소분류': post_board_list,\n","        '제목': title_list,\n","        '날짜': date_list,\n","        '본문': content_list,\n","        '댓글': review_list\n","    })\n","    \n","    file_path = os.path.join(save_path, f'[{project_name}]Crawling_{channel}_{word}_{name}.csv')\n","    data.to_csv(file_path, index=False)"]},{"cell_type":"markdown","id":"d3uiUZsRgTG1","metadata":{"id":"d3uiUZsRgTG1"},"source":["- 누가 크롤링한 건지 확인할 수 있도록 키워드, 담당자 이름을 꼭 파일명에 넣어주세요!\n","- 어떤 키워드로 검색했을 때 나온 결과인지 알 수 있도록 키워드 꼬옥 넣어주세요!"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":5}
